{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf56597-bf24-497c-bb0f-6df7e34c062a",
   "metadata": {},
   "source": [
    "# AI-Enhanced Risk Registry for ReadmitPredict: A Health Sector Project Management Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa1f24-ef9a-400a-90e6-1e45a359c42e",
   "metadata": {},
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29bc290-d78c-4822-b4fd-59f3dc23f615",
   "metadata": {},
   "source": [
    "This project builds upon **HTH 111: Project Management in the Health Sector**, a core course in the McMaster University Health Informatics Diploma program. In HTH 111, we focused on developing comprehensive project plans for health initiatives, including risk identification, mitigation, and stakeholder engagement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab472cb7-2106-46ba-a9bb-f8a689999ebd",
   "metadata": {},
   "source": [
    "### Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c83e888-c141-408f-b49d-4f2a1a096d78",
   "metadata": {},
   "source": [
    "Preventable 30-day hospital readmissions remain a critical challenge in U.S. healthcare. Nsama (2025) estimates that avoidable readmissions contribute to approximately 30% of wasteful spending, costing the system around $17 billion annually, while also driving up penalties under the Centers for Medicare & Medicaid Services (CMS) Hospital Readmissions Reduction Program (HRRP). In fiscal year 2026, more hospitals are expected to face increased penalties as pneumonia data is reinstated in performance calculations (Eastabrook, 2025). One Community Hospital, like many systems nationwide, continues to experience elevated readmission rates that inflate costs, strain resources, and compromise patient outcomes.\n",
    "\n",
    "To address this proactively and mitigate rising financial exposure in 2026, we propose **ReadmitPredict**: a cloud-based predictive analytics tool that enhances the validated LACE index with machine learning to deliver real-time, percentage-based readmission risk scores through an intuitive, EMR-integrated clinician dashboard. Featuring color-coded alerts (green <20%, yellow 20–50%, red >50%), factor explanations, and actionable flags, the tool empowers clinicians to make informed discharge decisions.\n",
    "\n",
    "Inspired by successful implementations such as Allina Health — which achieved a 10.3% overall reduction in potentially preventable readmissions (including 4.3% in high-risk and 21.3% in moderate/high-risk patients) through predictive analytics and process redesign (Health Catalyst, 2025) — ReadmitPredict targets a >30% reduction in 30-day readmissions within two years post-pilot. The focused rollout in Cardiology and Internal Medicine departments delivers the following key benefits:\n",
    "\n",
    "- Significant reduction in readmissions (>30% target), lowering CMS penalties and improving patient safety  \n",
    "- Cost avoidance through reduced penalties, shorter stays, and optimized resource use  \n",
    "- Enhanced clinician workflow with transparent, actionable risk insights  \n",
    "- Strategic alignment with organizational goals for quality care, efficiency, and data-driven decision-making\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67188bec-51f1-46dd-b322-d5ca6e7a0e48",
   "metadata": {},
   "source": [
    "**Triple Constraint Overview**\n",
    "\n",
    "| Constraint | Target        | Key Assurance                                         |\n",
    "|------------|---------------|-------------------------------------------------------|\n",
    "| Schedule   | 10–12 months  | Phased pilot approach with clear milestones            |\n",
    "| Budget     | ~$550,000     | Focused on cloud-based solution and existing EMR integration |\n",
    "| Scope      | Pilot in two departments | Excludes full rollout and new hardware |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9920d-924d-4d49-ae39-caa31bdc0f5e",
   "metadata": {},
   "source": [
    "With a realistic 10–12 month timeline and ~$550,000 budget, the project ensures HIPAA compliance, bias mitigation, and clinician-friendly design. ReadmitPredict positions One Community Hospital as a leader in proactive, data-driven care, delivering measurable strategic and financial value.This portfolio project extends the HTH 111 assignment by incorporating data analysis techniques to enhance risk management, demonstrating strong skills in both project management and data analytics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b33d3-4dce-4f07-8e80-7f876141ecd4",
   "metadata": {},
   "source": [
    "### Overview of Risk Management Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e4d50-90c3-446f-9c0f-25a0320c8027",
   "metadata": {},
   "source": [
    "Risk management in health projects (EHR implementations, predictive analytics tools) typically follows frameworks such as PMBOK or PRINCE2, emphasizing identification, assessment, mitigation, and monitoring. Common strategies include:\n",
    "\n",
    "- Qualitative assessment using likelihood-impact matrices\n",
    "- Quantitative modeling (Monte Carlo, machine learning)\n",
    "- Stakeholder crowdsourcing to uncover blind spots\n",
    "- Contingency planning for high-impact risks\n",
    "\n",
    "In this project we adopt a creative, AI-enhanced risk registry for ReadmitPredict. We collect risks via Google Forms, simulate historical data for ML training, predict escalation probabilities, and generate mitigation suggestions using generative AI. This data-driven approach integrates traditional PM strategies with modern analytics, enabling proactive decision-making to protect the triple constraints while addressing health-specific risks (HIPAA, ML bias, clinician adoption).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f7dcd-12ff-4b21-96a1-699d740fa308",
   "metadata": {},
   "source": [
    "### Data Collection Strategy\n",
    "\n",
    "Data collection is foundational to effective risk management, ensuring diverse inputs for comprehensive analysis.\n",
    "\n",
    "#### Google Forms for Stakeholder Input\n",
    "\n",
    "We designed an anonymous Google Form to gather risks from stakeholders (clinicians, IT, finance, etc.). The form includes fields for Risk Category, Description, Likelihood (1–5), Impact (1–5), Potential Triggers/Examples, and Mitigation Ideas, with optional Role/Department.\n",
    "\n",
    "**Form link**: https://forms.gle/ZSdRNrdyVaJMbfLF9\n",
    "\n",
    "Anonymity encourages honest feedback and aligns with health sector ethical considerations.\n",
    "\n",
    "#### Registry Samples Data Creation\n",
    "\n",
    "To populate the registry with realistic samples, we used **Grok AI** (xAI's Grok-4 model) to generate 20 factitious but plausible risk entries. Grok created balanced examples across categories (Technical, Ethical, Operational, Regulatory, Financial), with varied likelihood/impact scores and tailored triggers/mitigations based on healthcare IT contexts. This simulation strategy ensured a diverse dataset for testing without real stakeholder delays.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e0f54-1430-4c44-9c75-c21566518099",
   "metadata": {},
   "source": [
    "### Historical Data Creation Strategy\n",
    "\n",
    "To train the ML model for risk escalation prediction, we generated synthetic historical data mimicking past health tech projects.\n",
    "\n",
    "#### Simple Code Explanation\n",
    "\n",
    "The Python code uses NumPy and Pandas to create 500 rows with realistic but correlated distributions:\n",
    "\n",
    "- Features: Project_Type, Team_Size, Complexity_Score, etc.\n",
    "- Derived outcomes (Delay_Months, Budget_Overrun_Pct) incorporate correlations\n",
    "= Target (Risk_Escalation) defined logically with slight noise\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c3a9e7-e907-4214-829e-9c69375f239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Project_ID               Project_Type  Team_Size  Budget_Planned_K  \\\n",
      "0           1               Telemedicine         37       1426.904604   \n",
      "1           2  Clinical_Decision_Support          5        813.124225   \n",
      "2           3         EHR_Implementation         23        669.250151   \n",
      "3           4               Telemedicine          6       1092.867418   \n",
      "4           5               Telemedicine         48       1447.202646   \n",
      "\n",
      "   Timeline_Months_Planned  Complexity_Score Stakeholder_Engagement_Level  \\\n",
      "0                       11          4.647233                         High   \n",
      "1                        7          5.477184                       Medium   \n",
      "2                       16          7.481823                       Medium   \n",
      "3                        9          1.959209                         High   \n",
      "4                       20          2.260167                       Medium   \n",
      "\n",
      "  Training_Quality Vendor_Reliability  Budget_Overrun_Pct  Risk_Escalation  \\\n",
      "0           Medium             Medium           25.120679                0   \n",
      "1             High             Medium            8.000000                0   \n",
      "2              Low               High           25.393085                0   \n",
      "3           Medium             Medium           29.293243                0   \n",
      "4             High             Medium            9.621265                0   \n",
      "\n",
      "   Delay_Months  \n",
      "0      5.521430  \n",
      "1      3.473343  \n",
      "2      7.265392  \n",
      "3      6.237174  \n",
      "4      6.314558  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "n_projects = 300  # Simulate 300 past health tech projects (e.g., EHR/predictive tools)\n",
    "\n",
    "data = {\n",
    "    'Project_ID': range(1, n_projects + 1),\n",
    "    'Project_Type': np.random.choice(['EHR_Implementation', 'Predictive_Analytics', 'Telemedicine', 'Clinical_Decision_Support'], n_projects),\n",
    "    'Team_Size': np.random.randint(5, 50, n_projects),\n",
    "    'Budget_Planned_K': np.random.uniform(200, 2000, n_projects),  # in $K\n",
    "    'Timeline_Months_Planned': np.random.randint(6, 24, n_projects),\n",
    "    'Complexity_Score': np.random.uniform(1, 10, n_projects),  # 1=simple, 10=high (e.g., multi-dept integration)\n",
    "    'Stakeholder_Engagement_Level': np.random.choice(['High', 'Medium', 'Low'], n_projects, p=[0.3, 0.5, 0.2]),\n",
    "    'Training_Quality': np.random.choice(['High', 'Medium', 'Low'], n_projects, p=[0.4, 0.4, 0.2]),\n",
    "    'Vendor_Reliability': np.random.choice(['High', 'Medium', 'Low'], n_projects),\n",
    "    # Target variables (what we predict)\n",
    "    'Budget_Overrun_Pct': np.random.normal(15, 10, n_projects).clip(0, 100),  # % overrun\n",
    "    'Risk_Escalation': np.random.choice([0, 1], n_projects, p=[0.65, 0.35])  # 1 = major risk occurred (e.g., >20% overrun or >3 month delay)\n",
    "}\n",
    "\n",
    "\n",
    "data['Delay_Months'] = (\n",
    "    np.random.poisson(2, n_projects) +\n",
    "    np.random.uniform(0, 5, n_projects) * (10 - data['Complexity_Score']) / 10\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add some realistic correlations\n",
    "df['Delay_Months'] = df['Delay_Months'] + (df['Training_Quality'].map({'Low': 4, 'Medium': 1, 'High': 0}))\n",
    "df['Budget_Overrun_Pct'] += (df['Stakeholder_Engagement_Level'].map({'Low': 20, 'Medium': 8, 'High': 0}))\n",
    "\n",
    "df.to_csv('data/historical_healthtech_project_risks.csv', index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a65440-3b44-4fcb-ad73-30014ba5dcc4",
   "metadata": {},
   "source": [
    "### Model Specifications and Threshold Usage\n",
    "\n",
    "We used a **Random Forest Classifier** (scikit-learn) to predict Risk_Escalation (0/1).\n",
    "\n",
    "**Specifications:**\n",
    "\n",
    "- Preprocessing: OneHotEncoder for categoricals\n",
    "- Model: `RandomForestClassifier(n_estimators=300, class_weight={0:3.0, 1:1.0}, max_depth=9, min_samples_leaf=5, random_state=42)`\n",
    "- Evaluation: Accuracy ~0.74, macro F1 ~0.61 (focus on balanced performance given ~76% escalation rate)\n",
    "\n",
    "**Threshold tuning**: Default 0.5 adjusted to **0.60** after testing 0.50–0.75 range — chosen for high recall on escalation events (minimize missed risks) while improving precision on non-escalation cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5325b879-3eb2-4a8d-a38b-6382ce61d73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.40      0.38        25\n",
      "           1       0.85      0.83      0.84       100\n",
      "\n",
      "    accuracy                           0.74       125\n",
      "   macro avg       0.61      0.61      0.61       125\n",
      "weighted avg       0.75      0.74      0.75       125\n",
      "\n",
      "\n",
      "Class distribution: Risk_Escalation\n",
      "1    0.762\n",
      "0    0.238\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "n_projects = 500  # Increase size for better learning\n",
    "\n",
    "# Base features\n",
    "data = {\n",
    "    'Project_ID': range(1, n_projects + 1),\n",
    "    'Project_Type': np.random.choice(['EHR_Implementation', 'Predictive_Analytics', 'Telemedicine', 'Clinical_Decision_Support'], n_projects),\n",
    "    'Team_Size': np.random.randint(5, 50, n_projects),\n",
    "    'Budget_Planned_K': np.random.uniform(200, 2000, n_projects),\n",
    "    'Timeline_Months_Planned': np.random.randint(6, 24, n_projects),\n",
    "    'Complexity_Score': np.random.uniform(1, 10, n_projects),\n",
    "    'Stakeholder_Engagement_Level': np.random.choice(['High', 'Medium', 'Low'], n_projects, p=[0.3, 0.5, 0.2]),\n",
    "    'Training_Quality': np.random.choice(['High', 'Medium', 'Low'], n_projects, p=[0.4, 0.4, 0.2]),\n",
    "    'Vendor_Reliability': np.random.choice(['High', 'Medium', 'Low'], n_projects),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Realistic derived outcomes (these influence escalation)\n",
    "df['Delay_Months'] = (\n",
    "    np.random.poisson(1.5, n_projects) +                  # base poisson noise\n",
    "    (10 - df['Complexity_Score']) * 0.4 +                 # lower complexity → fewer delays\n",
    "    df['Training_Quality'].map({'Low': 4.0, 'Medium': 1.5, 'High': 0.2}) +\n",
    "    df['Stakeholder_Engagement_Level'].map({'Low': 3.5, 'Medium': 1.0, 'High': 0.3}) +\n",
    "    df['Vendor_Reliability'].map({'Low': 3.0, 'Medium': 1.0, 'High': 0.4})\n",
    ").clip(0, 15)\n",
    "\n",
    "df['Budget_Overrun_Pct'] = (\n",
    "    np.random.normal(12, 8, n_projects) +\n",
    "    (df['Complexity_Score'] - 5) * 2.5 +                  # higher complexity → more overrun\n",
    "    df['Training_Quality'].map({'Low': 18, 'Medium': 6, 'High': -2}) +\n",
    "    df['Stakeholder_Engagement_Level'].map({'Low': 15, 'Medium': 5, 'High': -3})\n",
    ").clip(0, 80)\n",
    "\n",
    "# Now define target logically (escalation if delay >3 months OR overrun >20%)\n",
    "df['Risk_Escalation'] = ((df['Delay_Months'] > 4.5) | (df['Budget_Overrun_Pct'] > 25)).astype(int)\n",
    "\n",
    "#add some pure randomness/noise so not everything is deterministic\n",
    "df['Risk_Escalation'] = df['Risk_Escalation'] ^ np.random.choice([0,1], size=n_projects, p=[0.85, 0.15])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(['Project_ID', 'Delay_Months', 'Budget_Overrun_Pct', 'Risk_Escalation'], axis=1)\n",
    "y = df['Risk_Escalation']\n",
    "\n",
    "cat_cols = ['Project_Type', 'Stakeholder_Engagement_Level', 'Training_Quality', 'Vendor_Reliability']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=300, max_depth=9, class_weight={0: 3.0, 1: 1.0},min_samples_leaf=5, random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'models/risk_predictor_model.pkl')\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"\\nClass distribution:\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945359b8-e82b-46f1-8554-7e7243d66301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.40      0.38        25\n",
      "           1       0.85      0.83      0.84       100\n",
      "\n",
      "    accuracy                           0.74       125\n",
      "   macro avg       0.61      0.61      0.61       125\n",
      "weighted avg       0.75      0.74      0.75       125\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold 0.60:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.68      0.49        25\n",
      "           1       0.90      0.73      0.81       100\n",
      "\n",
      "    accuracy                           0.72       125\n",
      "   macro avg       0.64      0.71      0.65       125\n",
      "weighted avg       0.80      0.72      0.74       125\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold 0.65:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.72      0.46        25\n",
      "           1       0.90      0.64      0.75       100\n",
      "\n",
      "    accuracy                           0.66       125\n",
      "   macro avg       0.62      0.68      0.60       125\n",
      "weighted avg       0.79      0.66      0.69       125\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold 0.70:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.84      0.43        25\n",
      "           1       0.92      0.48      0.63       100\n",
      "\n",
      "    accuracy                           0.55       125\n",
      "   macro avg       0.61      0.66      0.53       125\n",
      "weighted avg       0.80      0.55      0.59       125\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold 0.75:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.96      0.38        25\n",
      "           1       0.96      0.24      0.38       100\n",
      "\n",
      "    accuracy                           0.38       125\n",
      "   macro avg       0.60      0.60      0.38       125\n",
      "weighted avg       0.82      0.38      0.38       125\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Try different thresholds\n",
    "for thresh in [0.5, 0.6, 0.65, 0.7, 0.75]:\n",
    "    preds_custom = (probs >= thresh).astype(int)\n",
    "    print(f\"Threshold {thresh:.2f}:\")\n",
    "    print(classification_report(y_test, preds_custom, zero_division=0))\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db59ee8f-3dae-48ff-a7f3-f4ce17ce5713",
   "metadata": {},
   "source": [
    "### Mapping Data Model to Response Data\n",
    "\n",
    "To apply the model to form responses, we map qualitative fields to training features:\n",
    "\n",
    "- Fixed project values: Project_Type = 'Predictive_Analytics', Team_Size = 15, Budget = 550, Timeline = 11\n",
    "- Mapped: Stakeholder_Engagement_Level from Role/Department (e.g., IT/Compliance = 'High')\n",
    "- Derived: Complexity_Score = ((Likelihood + Impact)/2 × category_boost).clip(1,10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d3d941-16fe-4134-a016-9c236234e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20, 8)\n",
      "Columns: ['Timestamp', 'Risk Category', 'Risk Description', 'Likelihood', 'Impact', 'Your Role/Department', 'Potential Triggers / Examples: ', 'Mitigation Ideas: ']\n",
      "\n",
      "First few rows:\n",
      "\n",
      "                Timestamp Risk Category  \\\n",
      "0 2026-01-28 15:04:32.359     Technical   \n",
      "1 2026-01-28 15:07:48.820      Ethical    \n",
      "2 2026-01-28 15:09:21.265  Operational    \n",
      "3 2026-01-28 15:11:10.590    Regulatory   \n",
      "4 2026-01-28 15:12:15.766     Financial   \n",
      "\n",
      "                                    Risk Description  Likelihood  Impact  \\\n",
      "0  Delays or failures in integrating ReadmitPredi...           4       5   \n",
      "1  Model may produce inaccurate risk scores for r...           3       4   \n",
      "2  Clinicians resist using the new dashboard due ...           4       4   \n",
      "3  Changes to CMS HRRP rules (e.g., pneumonia rei...           3       5   \n",
      "4  Budget overrun due to unexpected cloud computi...           3       4   \n",
      "\n",
      "  Your Role/Department                    Potential Triggers / Examples:   \\\n",
      "0                   IT  Vendor API changes mid-project, mismatched dat...   \n",
      "1    Internal Medicine  Training data skewed toward urban hospital adm...   \n",
      "2           Cardiology  Dashboard alerts interrupt rounding, or color-...   \n",
      "3           Compliance  2026 policy update expands metrics, requiring ...   \n",
      "4              Finance  Higher-than-planned API calls during testing o...   \n",
      "\n",
      "                                  Mitigation Ideas:   \n",
      "0  Conduct early API compatibility testing with v...  \n",
      "1  Perform regular bias audits using fairness too...  \n",
      "2  Run clinician-led demo sessions and feedback l...  \n",
      "3  Build modular model architecture for fast retr...  \n",
      "4  Set monthly burn-rate tracking dashboard, prio...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file \n",
    "df_responses = pd.read_excel('data/Responses.xlsx')   \n",
    "\n",
    "print(\"Shape:\", df_responses.shape)\n",
    "print(\"Columns:\", df_responses.columns.tolist())\n",
    "print(\"\\nFirst few rows:\\n\")\n",
    "print(df_responses.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da44d72f-9b09-4faf-aede-4941f5468790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stakeholder_Engagement_Level\n",
      "High      15\n",
      "Medium     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df_model with EXACTLY the columns the model expects\n",
    "required_columns = [\n",
    "    'Project_Type',\n",
    "    'Team_Size',\n",
    "    'Budget_Planned_K',\n",
    "    'Timeline_Months_Planned',\n",
    "    'Complexity_Score',\n",
    "    'Stakeholder_Engagement_Level',\n",
    "    'Training_Quality',\n",
    "    'Vendor_Reliability'\n",
    "]\n",
    "\n",
    "df_model = pd.DataFrame(index=df_responses.index)  # same number of rows\n",
    "\n",
    "# Required categorical columns (must match training exactly)\n",
    "df_model['Project_Type'] = 'Predictive_Analytics'  # most similar to ReadmitPredict\n",
    "df_model['Vendor_Reliability'] = 'Medium'          # default\n",
    "\n",
    "df_model['Training_Quality'] = df_responses['Risk Category'].map({\n",
    "    'Operational': 'Low',      # e.g. adoption/training risks imply weaker training\n",
    "    'Technical': 'Medium',\n",
    "    'Ethical': 'High',         # bias mitigation might require strong training\n",
    "    'Financial': 'Medium',\n",
    "    'Regulatory': 'High'\n",
    "}).fillna('Medium')\n",
    "\n",
    "engagement_map = {\n",
    "    'IT': 'High',\n",
    "    'Compliance': 'High',\n",
    "    'Internal Medicine': 'High',\n",
    "    'Cardiology': 'High',\n",
    "    'Finance': 'Medium',\n",
    "    'Prefer not to say': 'Medium',\n",
    "    # Add fallback\n",
    "}\n",
    "\n",
    "df_model['Stakeholder_Engagement_Level'] = df_responses['Your Role/Department'].map(engagement_map).fillna('Medium')\n",
    "\n",
    "# Optional: print the distribution to check it looks reasonable\n",
    "print(df_model['Stakeholder_Engagement_Level'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3416d88-8a38-43a5-a0c8-ff0943a83cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared input shape: (20, 14)\n",
      "           Project_Type Vendor_Reliability Training_Quality  \\\n",
      "0  Predictive_Analytics             Medium           Medium   \n",
      "1  Predictive_Analytics             Medium           Medium   \n",
      "2  Predictive_Analytics             Medium           Medium   \n",
      "\n",
      "  Stakeholder_Engagement_Level  Complexity_Score  Team_Size  Budget_Planned_K  \\\n",
      "0                         High          5.923620         15               550   \n",
      "1                         High          4.852143         15               550   \n",
      "2                         High          4.695982         15               550   \n",
      "\n",
      "   Timeline_Months_Planned                          Original_Risk_Description  \\\n",
      "0                       11  Delays or failures in integrating ReadmitPredi...   \n",
      "1                       11  Model may produce inaccurate risk scores for r...   \n",
      "2                       11  Clinicians resist using the new dashboard due ...   \n",
      "\n",
      "  Original_Category  Likelihood  Impact Triggers Mitigation  \n",
      "0         Technical           4       5                      \n",
      "1          Ethical            3       4                      \n",
      "2      Operational            4       4                      \n"
     ]
    }
   ],
   "source": [
    "# Numeric columns - derive where possible\n",
    "#if 'Likelihood' in df_responses.columns and 'Impact' in df_responses.columns:\n",
    "    #df_model['Complexity_Score'] = (df_responses['Likelihood'] + df_responses['Impact']) / 2 * 2  # scale to ~1-10 range\n",
    "#else:\n",
    "    #df_model['Complexity_Score'] = 5.0  # neutral default\n",
    "\n",
    "# Instead of /2 *2, use a stronger multiplier or add category boost\n",
    "base_complex = (df_responses['Likelihood'] + df_responses['Impact']) / 2\n",
    "category_boost = df_responses['Risk Category'].map({\n",
    "    'Technical': 1.4,      # integration is complex\n",
    "    'Regulatory': 1.5,\n",
    "    'Ethical': 1.3,\n",
    "    'Operational': 1.2,\n",
    "    'Financial': 1.0\n",
    "}).fillna(1.0)\n",
    "\n",
    "df_model['Complexity_Score'] = (base_complex * category_boost).clip(1, 10)\n",
    "\n",
    "#Add small random/project-specific variation \n",
    "np.random.seed(42)\n",
    "df_model['Complexity_Score'] += np.random.uniform(-1.5, 1.5, len(df_model))\n",
    "df_model['Complexity_Score'] = df_model['Complexity_Score'].clip(1, 10)\n",
    "\n",
    "# Add other numerics if you have proxies (or use defaults)\n",
    "df_model['Team_Size'] = 15                     # average for pilot project\n",
    "df_model['Budget_Planned_K'] = 550             # from your exec summary\n",
    "df_model['Timeline_Months_Planned'] = 11       # mid of 10-12 months\n",
    "\n",
    "# Copy over useful original columns for later reference\n",
    "df_model['Original_Risk_Description'] = df_responses.get('Risk Description', '')\n",
    "df_model['Original_Category'] = df_responses.get('Risk Category', '')\n",
    "df_model['Likelihood'] = df_responses.get('Likelihood', 3)\n",
    "df_model['Impact'] = df_responses.get('Impact', 3)\n",
    "df_model['Triggers'] = df_responses.get('Potential Triggers / Examples', '')\n",
    "df_model['Mitigation'] = df_responses.get('Mitigation Ideas', '')\n",
    "\n",
    "print(\"Prepared input shape:\", df_model.shape)\n",
    "print(df_model.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fae978-a483-4c01-8be5-1f2f664ce2a7",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074ea7ab-2c0b-4de8-a0f6-4410f83ecd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions complete! Sample output:\n",
      "\n",
      "  Original_Category                          Original_Risk_Description  \\\n",
      "0         Technical  Delays or failures in integrating ReadmitPredi...   \n",
      "1          Ethical   Model may produce inaccurate risk scores for r...   \n",
      "2      Operational   Clinicians resist using the new dashboard due ...   \n",
      "3        Regulatory  Changes to CMS HRRP rules (e.g., pneumonia rei...   \n",
      "4         Financial  Budget overrun due to unexpected cloud computi...   \n",
      "5         Technical  Data security breach during cloud-based real-t...   \n",
      "6      Operational   Staff turnover delays training and knowledge t...   \n",
      "7          Ethical   Over-reliance on tool leads to reduced clinica...   \n",
      "\n",
      "   Manual_Risk_Score  Escalation_Probability_%  Predicted_Escalation  \\\n",
      "0                 20                 63.438470                     1   \n",
      "1                 12                 60.675323                     1   \n",
      "2                 16                 61.010617                     1   \n",
      "3                 15                 37.603948                     0   \n",
      "4                 12                 63.608403                     1   \n",
      "5                 10                 59.395771                     0   \n",
      "6                 12                 63.467175                     1   \n",
      "7                 12                 60.483472                     1   \n",
      "\n",
      "  Risk_Level  \n",
      "0     Medium  \n",
      "1     Medium  \n",
      "2     Medium  \n",
      "3        Low  \n",
      "4     Medium  \n",
      "5     Medium  \n",
      "6     Medium  \n",
      "7     Medium  \n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained pipeline\n",
    "model = joblib.load('models/risk_predictor_model.pkl')   # adjust path/filename\n",
    "\n",
    "# Predict probabilities and custom threshold\n",
    "probs = model.predict_proba(df_model)[:, 1]   # probability of escalation (class 1)\n",
    "\n",
    "df_model['Escalation_Probability_%'] = probs * 100\n",
    "df_model['Predicted_Escalation'] = (probs >= 0.60).astype(int)  # your chosen threshold\n",
    "\n",
    "# Optional: Classic manual risk score for comparison\n",
    "df_model['Manual_Risk_Score'] = df_model['Likelihood'] * df_model['Impact']\n",
    "df_model['Risk_Level'] = pd.cut(\n",
    "    df_model['Escalation_Probability_%'],\n",
    "    bins=[0, 40, 65, 100],\n",
    "    labels=['Low', 'Medium', 'High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Save enriched results\n",
    "df_model['Score_Discrepancy'] = df_model['Escalation_Probability_%'] - (df_model['Likelihood'] * df_model['Impact'] / 25 * 100)  # normalize manual to 0-100 scale\n",
    "\n",
    "df_model.to_excel('data/Final_ReadmitPredict_Risk_Predictions.xlsx', index=False)\n",
    "\n",
    "print(\"\\nPredictions complete! Sample output:\\n\")\n",
    "print(df_model[['Original_Category', 'Original_Risk_Description', 'Manual_Risk_Score', \n",
    "                'Escalation_Probability_%', 'Predicted_Escalation', 'Risk_Level']].head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7eb509-e682-4f30-bf47-f0db674c3fac",
   "metadata": {},
   "source": [
    "### AI Mitigation Strategy and Code\n",
    "\n",
    "We integrated **generative AI** (OpenAI GPT-4o-mini via ChatGPT subscription) to auto-generate 3–4 mitigation suggestions per risk.\n",
    "\n",
    "#### Strategy\n",
    "\n",
    "- Context-aware prompts include risk description, triggers, budget (~$550K), and timeline (10–12 months)\n",
    "- Outputs are supplementary — subject to human review\n",
    "- Results added as new column and visualized in dashboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e26d1aa-61f9-42c2-a244-5923decc9667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating AI mitigation suggestions...\n",
      "Done! Results saved to: data/Responses_with_AI_Mitigations.xlsx\n",
      "\n",
      "Sample:\n",
      "                                    Risk Description  \\\n",
      "0  Delays or failures in integrating ReadmitPredi...   \n",
      "1  Model may produce inaccurate risk scores for r...   \n",
      "2  Clinicians resist using the new dashboard due ...   \n",
      "\n",
      "                            AI_Generated_Mitigations  \n",
      "0  1. **Early Stakeholder Engagement**: Initiate ...  \n",
      "1  1. **Diverse Data Collection**: Collaborate wi...  \n",
      "2  1. **User-Centric Design Workshops**: Conduct ...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Load your data (Responses.xlsx or the enriched one)\n",
    "df = pd.read_excel('data/Responses.xlsx')  # or 'Responses_with_Predictions.xlsx'\n",
    "\n",
    "load_dotenv(\"process.env\")\n",
    "\n",
    "# Initialize OpenAI client (automatically uses your env variable)\n",
    "client = OpenAI()  # If you hardcoded: OpenAI(api_key=\"sk-your-key-here\")\n",
    "\n",
    "# Choose a strong model (your subscription gives access to these)\n",
    "MODEL = \"gpt-4o-mini\"   # fast & cheap — great for bulk\n",
    "# Alternatives: \"gpt-4o\" (more powerful), \"o1-mini\" (strong reasoning)\n",
    "\n",
    "def generate_mitigation_suggestions(row):\n",
    "    risk_desc = row['Risk Description'] if 'Risk Description' in row else row.get('Original_Risk_Description', '')\n",
    "    triggers  = row['Potential Triggers / Examples'] if 'Potential Triggers / Examples' in row else ''\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in healthcare project risk management.\n",
    "    For the following risk in a hospital readmission prediction tool project (ReadmitPredict):\n",
    "    \n",
    "    Risk: {risk_desc}\n",
    "    Potential triggers: {triggers}\n",
    "    \n",
    "    Generate 3-4 concise, practical mitigation strategies or actions.\n",
    "    Focus on feasibility within a 10-12 month pilot budget of ~$550K.\n",
    "    Number them 1-4 and keep each suggestion 1-2 sentences.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,   # 0.0 = deterministic, 0.7 = creative but safe\n",
    "            max_tokens=300\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Apply to every row (may take a few seconds per row depending on volume)\n",
    "print(\"Generating AI mitigation suggestions...\")\n",
    "df['AI_Generated_Mitigations'] = df.apply(generate_mitigation_suggestions, axis=1)\n",
    "\n",
    "# Save the updated file\n",
    "output_file = 'data/Responses_with_AI_Mitigations.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Done! Results saved to: {output_file}\")\n",
    "print(\"\\nSample:\")\n",
    "print(df[['Risk Description', 'AI_Generated_Mitigations']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6ca11-dc18-47de-8721-883b6b0bbd6c",
   "metadata": {},
   "source": [
    "### Dashboard Overview\n",
    "\n",
    "An interactive dashboard was built using **Plotly Dash** to visualize the risk registry.\n",
    "\n",
    "Key components:\n",
    "\n",
    "- Category filter\n",
    "- KPI cards (total risks, high risks, avg AI probability, % flagged)\n",
    "- Risk heat map (Likelihood × Impact scatter)\n",
    "- Word cloud from AI mitigations\n",
    "- Box plot: AI probability by category\n",
    "- Pie chart: Flagged vs not flagged\n",
    "- Top 10 words bar chart from AI mitigations\n",
    "- Detailed table with conditional formatting\n",
    "\n",
    "The dashboard demonstrates how data analysis supports project management tasks: real-time prioritization, theme identification, and stakeholder communication.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1c393-d70d-4742-a845-3a0a3df24355",
   "metadata": {},
   "source": [
    "**Dashboard link on Plotly Cloud**: https://c97adaa2-b827-4a32-ac7d-a7faec385ac2.plotly.app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd09e99c-2d1a-4e11-8a1c-983f7441b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c80c14fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Load your enriched data\n",
    "df_ai = pd.read_excel('data/Responses_with_AI_Mitigations.xlsx')  \n",
    "df = pd.read_excel('data/Final_ReadmitPredict_Risk_Predictions.xlsx')\n",
    "df['AI_Generated_Mitigations'] = df_ai['AI_Generated_Mitigations']\n",
    "\n",
    "# Helper: generate word cloud as base64\n",
    "def generate_wordcloud(text_column):\n",
    "    if text_column.empty or text_column.isna().all():\n",
    "        return \"\"\n",
    "    text = ' '.join(text_column.dropna().astype(str))\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, height=400,\n",
    "        background_color='white',\n",
    "        min_font_size=10, max_font_size=150,\n",
    "        colormap='viridis'\n",
    "    ).generate(text)\n",
    "    \n",
    "    img = io.BytesIO()\n",
    "    wordcloud.to_image().save(img, format='PNG')\n",
    "    img.seek(0)\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(img.read()).decode()\n",
    "\n",
    "# Helper: get top 10 words from AI mitigations\n",
    "def get_top_words(text_column, n=10):\n",
    "    text = ' '.join(text_column.dropna().astype(str)).lower()\n",
    "    # Clean text: remove punctuation, numbers, short words\n",
    "    words = re.findall(r'\\b[a-z]{3,}\\b', text)\n",
    "    # Remove common stop words (simple list)\n",
    "    stop_words = {'the', 'and', 'for', 'with', 'the', 'to', 'in', 'of', 'a', 'on', 'at', 'by', 'as', 'is'}\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    \n",
    "    counter = Counter(words)\n",
    "    top = counter.most_common(n)\n",
    "    if not top:\n",
    "        return pd.DataFrame({'word': [], 'count': []})\n",
    "    return pd.DataFrame(top, columns=['word', 'count'])\n",
    "\n",
    "# Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"ReadmitPredict Risk Registry Dashboard\", style={'textAlign': 'center', 'color': '#2c3e50'}),\n",
    "    html.Hr(),\n",
    "\n",
    "    # Filter\n",
    "    html.Div([\n",
    "        html.Label(\"Filter by Category:\", style={'fontWeight': 'bold'}),\n",
    "        dcc.Dropdown(\n",
    "            id='category-filter',\n",
    "            options=[{'label': cat, 'value': cat} for cat in sorted(df['Original_Category'].unique())],\n",
    "            value=None,\n",
    "            placeholder=\"All categories\",\n",
    "            multi=True,\n",
    "            style={'width': '100%'}\n",
    "        ),\n",
    "    ], style={'width': '60%', 'margin': '20px auto'}),\n",
    "\n",
    "    # KPI cards\n",
    "    html.Div([\n",
    "        html.Div(id='kpi-total', className='kpi-card'),\n",
    "        html.Div(id='kpi-high', className='kpi-card'),\n",
    "        html.Div(id='kpi-avg-prob', className='kpi-card'),\n",
    "        html.Div(id='kpi-flagged', className='kpi-card'),\n",
    "    ], style={'display': 'flex', 'justifyContent': 'center', 'gap': '20px', 'margin': '20px'}),\n",
    "\n",
    "    # Row 1: Risk Matrix + Word Cloud\n",
    "    html.Div([\n",
    "        dcc.Graph(id='risk-matrix', style={'width': '50%', 'display': 'inline-block'}),\n",
    "        html.Div([\n",
    "            html.H3(\"Word Cloud – AI Mitigation Themes\", style={'textAlign': 'center'}),\n",
    "            html.Img(id='wordcloud', style={'width': '90%', 'margin': 'auto', 'display': 'block'})\n",
    "        ], style={'width': '50%', 'display': 'inline-block', 'verticalAlign': 'top'})\n",
    "    ], style={'display': 'flex', 'margin': '20px'}),\n",
    "\n",
    "    # Row 2: Box plot + Pie + Top 10 Words Bar\n",
    "    html.Div([\n",
    "        dcc.Graph(id='prob-by-category', style={'width': '33%', 'display': 'inline-block'}),\n",
    "        dcc.Graph(id='escalation-pie', style={'width': '33%', 'display': 'inline-block'}),\n",
    "        dcc.Graph(id='top-words-bar', style={'width': '33%', 'display': 'inline-block'}),\n",
    "    ], style={'display': 'flex', 'margin': '20px'}),\n",
    "\n",
    "    # Detailed table\n",
    "    html.H3(\"Risk Details\", style={'textAlign': 'center'}),\n",
    "    dash_table.DataTable(\n",
    "        id='risk-table',\n",
    "        columns=[\n",
    "            {\"name\": \"Category\", \"id\": \"Original_Category\"},\n",
    "            {\"name\": \"Description\", \"id\": \"Original_Risk_Description\"},\n",
    "            {\"name\": \"Manual Score\", \"id\": \"Manual_Risk_Score\"},\n",
    "            {\"name\": \"AI Probability %\", \"id\": \"Escalation_Probability_%\"},\n",
    "            {\"name\": \"Flagged\", \"id\": \"Predicted_Escalation\"},\n",
    "            {\"name\": \"AI Mitigations\", \"id\": \"AI_Generated_Mitigations\"}\n",
    "        ],\n",
    "        style_table={'overflowX': 'auto'},\n",
    "        style_cell={'textAlign': 'left', 'padding': '10px', 'whiteSpace': 'normal', 'height': 'auto'},\n",
    "        style_data_conditional=[\n",
    "            {'if': {'filter_query': '{Predicted_Escalation} eq 1'}, 'backgroundColor': '#ffebee'},\n",
    "            {'if': {'filter_query': '{Risk_Level} eq \"High\"'}, 'color': '#c0392b', 'fontWeight': 'bold'},\n",
    "        ],\n",
    "        page_size=12\n",
    "    ),\n",
    "], style={'padding': '20px', 'fontFamily': 'Arial, sans-serif'})\n",
    "\n",
    "# Callback\n",
    "@app.callback(\n",
    "    [\n",
    "        Output('risk-matrix', 'figure'),\n",
    "        Output('wordcloud', 'src'),\n",
    "        Output('prob-by-category', 'figure'),\n",
    "        Output('escalation-pie', 'figure'),\n",
    "        Output('top-words-bar', 'figure'),\n",
    "        Output('risk-table', 'data'),\n",
    "        Output('kpi-total', 'children'),\n",
    "        Output('kpi-high', 'children'),\n",
    "        Output('kpi-avg-prob', 'children'),\n",
    "        Output('kpi-flagged', 'children'),\n",
    "    ],\n",
    "    [Input('category-filter', 'value')]\n",
    ")\n",
    "def update_dashboard(selected_categories):\n",
    "    dff = df.copy()\n",
    "    if selected_categories:\n",
    "        dff = dff[dff['Original_Category'].isin(selected_categories)]\n",
    "\n",
    "    # Risk matrix\n",
    "    fig_matrix = px.scatter(\n",
    "        dff,\n",
    "        x='Impact',\n",
    "        y='Likelihood',\n",
    "        size='Manual_Risk_Score',\n",
    "        color='Risk_Level',\n",
    "        hover_data=['Original_Risk_Description', 'Escalation_Probability_%', 'Original_Category'],\n",
    "        color_discrete_map={'Low': '#27ae60', 'Medium': '#f39c12', 'High': '#c0392b'},\n",
    "        title='Risk Heat Map (bubble size = Manual Score)'\n",
    "    )\n",
    "    fig_matrix.update_layout(xaxis_range=[0.5, 5.5], yaxis_range=[0.5, 5.5], height=550, width=650)\n",
    "\n",
    "    # Word cloud\n",
    "    wc_src = generate_wordcloud(dff['AI_Generated_Mitigations'])\n",
    "\n",
    "    # Probability by category (box)\n",
    "    fig_prob = px.box(\n",
    "        dff, x='Original_Category', y='Escalation_Probability_%',\n",
    "        color='Original_Category', title='AI Probability by Category',\n",
    "        height=450, width=650\n",
    "    )\n",
    "    fig_prob.update_layout(showlegend=False)\n",
    "\n",
    "    # Pie: Flagged vs Not\n",
    "    flagged_counts = dff['Predicted_Escalation'].value_counts().reset_index()\n",
    "    flagged_counts.columns = ['Flagged', 'Count']\n",
    "    flagged_counts['Flagged'] = flagged_counts['Flagged'].map({1: 'Flagged', 0: 'Not Flagged'})\n",
    "    fig_pie = px.pie(\n",
    "        flagged_counts, values='Count', names='Flagged',\n",
    "        title='AI-Flagged Risks (≥65%)',\n",
    "        color_discrete_sequence=['#e74c3c', '#3498db'],\n",
    "        height=450, width=650\n",
    "    )\n",
    "\n",
    "    # Top 10 words bar chart\n",
    "    top_words_df = get_top_words(dff['AI_Generated_Mitigations'], 10)\n",
    "    fig_top_words = px.bar(\n",
    "        top_words_df,\n",
    "        x='count',\n",
    "        y='word',\n",
    "        orientation='h',\n",
    "        title='Top 10 Words in AI Mitigation Suggestions',\n",
    "        text='count',\n",
    "        color='count',\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    fig_top_words.update_layout(\n",
    "        height=450, width=650,\n",
    "        xaxis_title=\"Frequency\",\n",
    "        yaxis_title=\"Word\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig_top_words.update_traces(textposition='auto')\n",
    "\n",
    "    # KPIs\n",
    "    total = len(dff)\n",
    "    high = len(dff[dff['Risk_Level'] == 'High'])\n",
    "    avg_prob = round(dff['Escalation_Probability_%'].mean(), 1) if total > 0 else 0\n",
    "    pct_flagged = round((len(dff[dff['Predicted_Escalation'] == 1]) / total * 100), 1) if total > 0 else 0\n",
    "\n",
    "    kpi_total   = html.Div([html.H4(\"Total Risks\"),   html.H2(total)],   className='kpi-card')\n",
    "    kpi_high    = html.Div([html.H4(\"High Risks\"),    html.H2(high)],    className='kpi-card')\n",
    "    kpi_avg     = html.Div([html.H4(\"Avg AI Prob\"),   html.H2(f\"{avg_prob}%\")], className='kpi-card')\n",
    "    kpi_flagged = html.Div([html.H4(\"% Flagged\"),     html.H2(f\"{pct_flagged}%\")], className='kpi-card')\n",
    "\n",
    "    return (\n",
    "        fig_matrix,\n",
    "        wc_src,\n",
    "        fig_prob,\n",
    "        fig_pie,\n",
    "        fig_top_words,\n",
    "        dff.to_dict('records'),\n",
    "        kpi_total, kpi_high, kpi_avg, kpi_flagged\n",
    "    )\n",
    "\n",
    "# CSS for KPI cards (same as before)\n",
    "app.index_string = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        {%metas%}\n",
    "        <title>ReadmitPredict Dashboard</title>\n",
    "        {%favicon%}\n",
    "        {%css%}\n",
    "        <style>\n",
    "            .kpi-card {\n",
    "                background: #f8f9fa;\n",
    "                border: 1px solid #ddd;\n",
    "                border-radius: 8px;\n",
    "                padding: 15px 25px;\n",
    "                min-width: 160px;\n",
    "                text-align: center;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .kpi-card h4 { margin: 0; font-size: 14px; color: #555; }\n",
    "            .kpi-card h2 { margin: 8px 0 0; font-size: 28px; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        {%app_entry%}\n",
    "        <footer>{%config%}{%scripts%}{%renderer%}</footer>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #app.run(debug=True, mode ='inline')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, mode ='inline')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ed974-b415-4972-bbde-8a06f1ed6961",
   "metadata": {},
   "source": [
    "### Code Best Practices, Model Tuning, and Acknowledgments\n",
    "\n",
    "#### Code Best Practices\n",
    "\n",
    "- Modular structure: separate files for data generation, model training, prediction, dashboard\n",
    "- Reproducibility: fixed random seeds `(np.random.seed(42))`\n",
    "- Error handling: try-except blocks for API calls, NaN checks\n",
    "- Documentation: comments, README.md, clear variable names\n",
    "- Version control: GitHub repository structure recommended\n",
    "\n",
    "#### Model Tuning\n",
    "\n",
    "- Addressed class imbalance with `class_weight={0:3.0, 1:1.0}`\n",
    "- Tuned threshold to 0.60 after evaluating 0.50–0.75 range\n",
    "- Focused on macro F1 and recall on escalation class (healthcare priority: avoid missing risks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37127a7b-9604-437b-8e26-cb0fa42cb3cd",
   "metadata": {},
   "source": [
    "### Acknowledgments\n",
    "\n",
    "This project was significantly enhanced by Grok AI (xAI's Grok-4 model), which provided guidance on data generation strategies, code structure, model tuning suggestions, dashboard design, and generative AI integration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3adbbc8-2265-489b-a5e8-ee0a6a866604",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d963b598-0760-4d12-bc36-6a2fc406f74e",
   "metadata": {},
   "source": [
    "Eastabrook, D. (2025). More hospitals to face high readmission penalties in fiscal 2026. AIMHI. Retrieved January 23, 2026 from https://aimhi.mobi/more-hospitals-to-face-high-readmission-penalties-in-fiscal-2026/\n",
    "\n",
    "Nsama, F. (2025). Assessing the Cost-Containment Effectiveness of AI-Based Predictive Models in Reducing Avoidable Readmissions and Overtreatment in US Medicare Hospitals. Applied Sciences, Computing, and Energy, 2(2), 452-466\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
